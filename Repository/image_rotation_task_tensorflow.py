# -*- coding: utf-8 -*-
"""Image Rotation Task- TensorFlow.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xtECY0waQco9QVgM9L57YUlU7tpiMUn0

# IMAGE ROTATION & DOWNSTREAM

from google.colab import drive
drive.mount('/content/drive')
"""

import os
import sys
import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import pandas as pd
from datetime import datetime
from tensorflow.keras.layers import (
    Activation, AveragePooling2D, BatchNormalization, Conv2D, Conv2DTranspose,
    Dense, Dropout, Flatten, Input, LeakyReLU, ReLU,MaxPooling2D, UpSampling2D,
    Concatenate,GlobalAveragePooling2D,Reshape)
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.models import Sequential, Model
from time import time
from IPython.display import clear_output
tf.autograph.set_verbosity(0)
import logging
logging.getLogger("tensorflow").setLevel(logging.ERROR)

batch_size = 16
num_channels = 3
image_size = 32
latent_dim=4096
epochs = 50
WORKDIR = "/received/content/drive/MyDrive/Rotation/Rotation Results/"

import tensorflow.keras as keras
(train_images, y_train), (test_images, y_test) = keras.datasets.cifar10.load_data()

"""train_images=train_images[0:1000,:,:,:]
test_images=test_images[0:500,:,:,:]
"""

print("train_images:", train_images.shape)
print("test_images:",test_images.shape)

"""## Rotation (Data Preprocessing)"""

#num_classes=np.unique(y_train).shape[0]
# np.concatenate([x_train, x_test])
total_sample=train_images.shape[0]

samples = train_images.astype("float32") / 255.0
samples = np.reshape(samples, (-1, 32, 32, 3))
#labels = tf.keras.utils.to_categorical(labels, num_classes)

# Create tf.data.Dataset.
dataset = tf.data.Dataset.from_tensor_slices(samples)#, labels))
dataset = dataset.shuffle(buffer_size=1024).batch(batch_size)

print(f"Shape of training images: {samples.shape}")
#print(f"Shape of training labels: {labels.shape}")
dataset

generator_in_channels = 3
discriminator_in_channels = generator_in_channels#*2
print(generator_in_channels, discriminator_in_channels)

from tensorflow.keras.applications.resnet import ResNet50#, ResNet152, ResNet101
# Create the discriminator.
inputs =keras.Input(shape=(32, 32, discriminator_in_channels))
base_model = ResNet50(input_tensor=inputs,include_top=False,weights='imagenet')
base_model.summary()

from tensorflow.keras.applications.resnet import ResNet50#, ResNet152, ResNet101
# Create the discriminator.
inputs =keras.Input(shape=(32, 32, discriminator_in_channels))
base_model = ResNet50(input_tensor=inputs,include_top=False,weights='imagenet')
input_=base_model.get_layer('conv3_block4_2_relu').output
#input_=base_model(training=False)
#a=Conv2D(64, (3, 3), strides=(2, 2), padding="same", activation='relu')(input_)
#a=Conv2D(128, (3, 3), strides=(2, 2), padding="same",activation='relu')(a)
a=GlobalAveragePooling2D()(input_)
output=Dense(1,activation='sigmoid')(a)
output_class=Dense(4,activation='softmax')(a)
discriminator = keras.Model(inputs, [output,output_class])
#discriminator.summary()


# Create the generator.
input_g =keras.Input(shape=(4096,))
input_gen=Reshape((4, 4,256))(input_g)

#input_gen = tf.keras.layers.Input(shape=[32, 32, 3], name='input_image')
#base_model = ResNet50(input_tensor=input_gen,include_top=False,weights='imagenet')
#input_g=base_model.get_layer('conv4_block5_out').output

#base_model_ = ResNet50(include_top=False,weights='imagenet',input_shape=(32,32,generator_in_channels))
#input_g=base_model(input_gen,training=False)
x =input_gen# tf.keras.layers.concatenate([input_g, input_g])
b=Conv2DTranspose(256, (3, 3), strides=(2, 2), padding="same",activation='relu')(x)
b=Conv2DTranspose(256, (3, 3), strides=(2, 2), padding="same",activation='relu')(b)
b=Conv2DTranspose(256, (3, 3), strides=(2, 2), padding="same",activation='relu')(b)
b=BatchNormalization()(b)
out_gen=Conv2D(3, (8, 8), padding="same",activation='tanh')(b)

generator = keras.Model(input_g,out_gen)
generator.summary()

"""base_model = ResNet50(include_top=True,weights='imagenet',input_shape=(224,224,discriminator_in_channels))
#base_model.summary()
a=base_model.get_layer('conv4_block6_out').output
a
"""

import numpy
from numpy import cov
from numpy import trace
from numpy import iscomplexobj
from scipy.linalg import sqrtm


from tensorflow.keras import backend as K

from math import log10
from skimage.metrics import structural_similarity, mean_squared_error



def SS_PSNR(y_t, y_p):
    psnr_val=0
    ssim_val=0
    dim,x,y,channel=y_t.shape
    for ii in range(dim):
        
        y_true=y_t[ii,:,:,:]
        y_pred=y_p[ii,:,:,:]
        ssim_=float(structural_similarity(y_true, y_pred, data_range=y_pred.max() - y_pred.min(),multichannel=True)*100)
        
        mse=0
        for i in range(channel):
            mse=mse+np.mean((y_true[:,:,i] - y_pred[:,:,i]) ** 2)
        mse=mse/channel
        if(mse == 0):
            psnr=100
        else:
            max_pixel = 255.0
            psnr = 10 * log10((max_pixel**2) / mse)
        ssim_val=ssim_val+ssim_    
        psnr_val=psnr_val+psnr
    return round(ssim_val/dim,2),round(psnr_val/dim,2)

# example of calculating the frechet inception distance in Keras for cifar10
import numpy
from numpy import cov
from numpy import trace
from numpy import iscomplexobj
from numpy import asarray
from numpy.random import shuffle
from scipy.linalg import sqrtm
from tensorflow.keras.applications.inception_v3 import InceptionV3
from tensorflow.keras.applications.inception_v3 import preprocess_input
from tensorflow.keras.datasets.mnist import load_data
from skimage.transform import resize
from tensorflow.keras.datasets import cifar10
 
def scale_images(images, new_shape):
    images_list = list()
    for image in images:
        new_image = resize(image, new_shape, 0)
        # store
        images_list.append(new_image)
    return asarray(images_list)
 
# calculate frechet inception distance
def calculate_fid(model, images1, images2):
   
    act1 = model.predict(images1)
    act2 = model.predict(images2)
  
    mu1, sigma1 = act1.mean(axis=0), cov(act1, rowvar=False)
    mu2, sigma2 = act2.mean(axis=0), cov(act2, rowvar=False)
   
    ssdiff = numpy.sum((mu1 - mu2)**2.0)
  
    covmean = sqrtm(sigma1.dot(sigma2))
    if iscomplexobj(covmean):
        covmean = covmean.real
    fid = ssdiff + trace(sigma1 + sigma2 - 2.0 * covmean)
    return fid

def FID_model():
    base_model = InceptionV3(include_top=False, weights='imagenet', input_shape=(75, 75, 3)) # shape of images after upsampling that inception will accept
    for layer in base_model.layers: 
        layer.trainable = False
    inputs = tf.keras.layers.Input(shape=(32, 32, 3))
    upsamp1 = tf.keras.layers.UpSampling2D((2,2))(inputs)
    upsamp2 = tf.keras.layers.UpSampling2D((2,2))(upsamp1)
    pre_trained_model = base_model(upsamp2)
    pre_trained_model=Flatten()(pre_trained_model)
    dense4 = tf.keras.layers.Dense(128, activation='relu')(pre_trained_model)
    predictions = tf.keras.layers.Dense(10, activation='softmax')(dense4)

    model = Model(inputs = inputs, outputs = predictions)
    model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])
    return model

# prepare the inception v3 model

#Simple_method, input (32,32,3)
finceptiond =FID_model()

#Scaled_method, input (299,299,3)
#finceptiond=InceptionV3(include_top=False, pooling='avg', input_shape=(299,299,3))


finceptiond.summary()

cross_entropy = tf.keras.losses.CategoricalCrossentropy(from_logits=True)
accuracy = tf.keras.metrics.CategoricalAccuracy()
loss=tf.keras.losses.Hinge()
def rot_loss(images, scale=1.0): #16,32,32,3
    rot_images,rot_label=rot_batch(images)
    total_rot_label=np.unique(rot_label)
    rot_label = tf.keras.utils.to_categorical(np.expand_dims(rot_label,axis=1),total_rot_label.shape[0])
    _,output_class=discriminator(rot_images,training=True)
    error_SS=cross_entropy(rot_label,output_class)
    return error_SS*scale


def discriminator_loss(real_output, fake_output):
    real_loss = loss(tf.ones_like(real_output), real_output)
    fake_loss = loss(tf.zeros_like(fake_output), fake_output)
    total_loss = real_loss + fake_loss
    return total_loss

def generator_loss(fake_output):
    return loss(tf.ones_like(fake_output), fake_output)



generator_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002)
discriminator_optimizer=tf.keras.optimizers.Adam(learning_rate=0.0002)

def rot_batch(x):
    batch_size=x.shape[0]
    x0=x.numpy().copy()
    x90=np.rot90(x,1, axes=(1,2))
    x180=np.rot90(x,2, axes=(1,2))
    x270=np.rot90(x,3, axes=(1,2))
    ret_t=np.concatenate((x0,x90,x180, x270), axis=0)
    y0=np.full((batch_size), 0)
    y90=np.full((batch_size), 1)
    y180=np.full((batch_size), 2)
    y270=np.full((batch_size), 3)
    ret_l=np.concatenate((y0,y90,y180, y270), axis=0)
    return ret_t,ret_l



def show_graph(ran,title,xl,yl, plotA,plotA_label,plotB,plotB_label,hm=2):
    if hm==1:
        plt.plot(range(1,ran+1,1), plotA, '-', label=plotA_label)
    else:
        plt.plot(range(1,ran+1,1), plotA, '-', label=plotA_label)
        plt.plot(range(1,ran+1,1), plotB, '-', label=plotB_label)
    plt.title(title)#)
    plt.xlabel(xl)#Epochs
    plt.ylabel(yl)#Loss
    plt.legend()
    plt.show()

"""## Rotation (Training)"""

latent_dim=4096
for x in dataset:
    batch_size = tf.shape(x)[0]
    random_latent_vectors = tf.random.normal(shape=(batch_size, latent_dim))
    #random_vector_labels = tf.concat([random_latent_vectors, y], axis=1)
    print(random_latent_vectors.shape)
    
    #y=generator.predict(x)
    #print(x.shape,y.shape)
    break

"""for x in dataset:
  print("Orignal: ",x.shape)
  print(tf.shape(x)[0])
  fake_images=generator(x,training=True)
  print("fake: ",fake_images.shape)
  real_output,_ = discriminator(x,training=True)
  print("real output: ",real_output.shape)
  fake_output,_ = discriminator(fake_images,training=True)
  print("fake output: ",fake_output.shape)
  errD = discriminator_loss(real_output,fake_output)
  print("error disc: ",errD)
  out_a,rot_label=rot_batch(x)
  print("rotated image: ",out_a.shape,"rotaded label: ",rot_label.shape)
  total_rot_label=np.unique(rot_label)
  print("labels: ",total_rot_label)
  rot_label_ = tf.keras.utils.to_categorical(np.expand_dims(rot_label,axis=1),total_rot_label.shape[0])
  print("ohe : ",rot_label_.shape)
  break
class_list = ['0 degree','90 degree','180 degree','270 degree']

fig = plt.figure(figsize=(15,4 ))
for i in range(4):
    ind=i*16 +0
    ax = plt.subplot(3, 5, i + 1)
    ax.imshow(out_a[ind,:,:,:])
    ax.axis("off")
    ax.title.set_text(class_list[int(rot_label[ind])])
"""

def train_step(x):
    batch_size = tf.shape(x)[0]
    rlv = tf.random.normal(shape=(batch_size, latent_dim))
    #print(random_vector_labels.shape)
    with tf.GradientTape() as disc_tape:
        #discriminator
        fake_images = generator(rlv,training=True)
        real_output,_ = discriminator(x,training=True)
        fake_output,_ = discriminator(fake_images,training=True)
        
        errD = discriminator_loss(real_output,fake_output)
        errD_rot=rot_loss(x)#,ss_loss_scale)
        disc_loss=errD+errD_rot
    discriminator_gradients = disc_tape.gradient(disc_loss,discriminator.trainable_variables)
    discriminator_optimizer.apply_gradients(zip(discriminator_gradients,discriminator.trainable_variables))   

    with tf.GradientTape() as gen_tape:
        #generator
        fake_images = generator(rlv,training=True)
        predictions,_ = discriminator(fake_images,training=False)
        errG=generator_loss(predictions)        
        errG_rot=rot_loss(fake_images)#,ss_loss_scale)
        gen_total_loss=errG+errG_rot
    generator_gradients = gen_tape.gradient(gen_total_loss,generator.trainable_variables)
    generator_optimizer.apply_gradients(zip(generator_gradients,generator.trainable_variables))   
    return gen_total_loss, errD,errG_rot,errD_rot

#Training
ss_loss_scale=1.0#0.2
total_batch=int(total_sample/batch_size)
gen_loss_t=[]
disc_loss_t=[]
rot_loss_t=[]
gen_rot_loss_t=[]
ssim_t=[]
psnr_t=[]
fid_t=[]
time_s=[]
index=0

validation_index=10000
for e in range(epochs):
    print('Epoch {}/{}'.format(e+1,epochs))
    stime=time()
    gent=0
    disct=0
    drott=0
    grott=0
    
    for batch_no,(x) in enumerate(dataset):
        index=index+1
        btime=time()
        gen_total_loss, disc_loss,errG_rot,errD_rot=train_step(x)
        gent=gent+gen_total_loss.numpy()
        disct=disct+disc_loss.numpy()
        drott=drott+errD_rot.numpy()
        grott=grott+errG_rot.numpy()
        
        
        print('[{}] -Epoch {} ({}/{}) gen loss: {}, disc loss: {}, rotary Loss {}, gen rotary Loss {}, time: {:.2f}s'.
              format(index,e+1,batch_no,total_batch, round(gen_total_loss.numpy(),4), round(disc_loss.numpy(),4)
                     ,round(errD_rot.numpy(),4),round(errG_rot.numpy(),4), time()-btime))
      
   
        if(index==validation_index):

            validation_index=validation_index+10000
            
            
            
            psnr_b=0
            ssim_b=0
            fid_b=0
            for b,(x) in enumerate(dataset):
                batch_size = tf.shape(x)[0]
                rlc = tf.random.normal(shape=(batch_size, latent_dim))
                fake_images = generator(rlc,training=False)
                fid = calculate_fid(finceptiond,x.numpy().astype('float32'),fake_images.numpy().astype('float32'))
                fid_b=fid_b+fid
                ssim,psnr=SS_PSNR(x.numpy(), fake_images.numpy())
                psnr_b=psnr_b+psnr
                print("Evaluation (FID,PSNR,SSIM): Iter. - ",str(validation_index), ", Batch - (",str(b),"/",str(total_batch),")")
                ssim_b=ssim_b+ssim
            fid_t.append(fid_b/total_batch)  
            psnr_t.append(psnr_b/total_batch)    
            ssim_t.append(ssim_b/total_batch)
            show_graph(len(psnr_t),'PSNR CGAN','Epochs','Accuracy',
                   psnr_t,'psnr',[],' ',hm=1)
            show_graph(len(ssim_t),'SSIM CGAN','Epochs','Accuracy',
                   ssim_t,'ssim',[],' ',hm=1)
            show_graph(len(fid_t),'FID CGAN','Epochs','Accuracy',
                   fid_t,'fid',[],' ',hm=1)

        
        
        
        
    
    gen_loss_t.append(gent/total_batch)
    disc_loss_t.append(disct/total_batch)
    rot_loss_t.append(drott/total_batch)
    gen_rot_loss_t.append(grott/total_batch)
    time_s.append(time()-stime)
    #clear_output(wait=True)
    
    print("_______________________________________________________________________________________________________")
    print('Epoch {}/{}: gen loss: {}, disc loss: {}, rotary Loss {}, gen rotary Loss {}, time: {:.2f}s'.
              format(e+1,epochs, round(gent/total_batch,4), round(disct/total_batch,4),round(drott/total_batch,4),
                     round(grott/total_batch,4), time()-stime))
    show_graph(len(gen_loss_t),'GENERATOR Discriminator Loss CGAN','Epochs','Loss',
               disc_loss_t,'Discriminator loss',gen_loss_t,'Generator loss',hm=2)
    show_graph(len(gen_rot_loss_t),'Auxilaty Rotary Loss','Epochs','Loss',
               rot_loss_t,'Discriminator Rotary loss',gen_rot_loss_t,'Generator Rotary loss',hm=2)
    generator.save(os.path.join(WORKDIR, 'generator_Epoch'+str(e+1)+'_rotary-model-cifar10.h5'))
    discriminator.save(os.path.join(WORKDIR, 'disciminator_Epoch'+str(e+1)+'_rotary-model-cifar10.h5'))

len(gen_loss_t),len(psnr_t)

len(ssim_t)
len(gen_loss_t)

"""for gta, dtb,rtc,grtd,sim,ps_nr,fidd ,ste in zip(gen_loss_t,disc_loss_t,rot_loss_t,gen_rot_loss_t,ssim_t,psnr_t,fid_t):
        print('gen loss: {}, disc loss: {}, rotary Loss {}, gen rotary Loss {}, SSIM {}, PSNR {}, FID {}'.
              format(gta, dtb,rtc,grtd,sim,ps_nr,fidd,ste))

## Rotation (Save/ Load Model)

generator.save(os.path.join(WORKDIR, 'generator_rotary-model-cifar10.h5'))
discriminator.save(os.path.join(WORKDIR, 'disciminator_rotary-model-cifar10.h5'))
"""

discriminator=tf.keras.models.load_model(os.path.join(WORKDIR, 'disciminator_Epoch50_rotary-model-cifar10.h5'))
discriminator.summary()

"""# DOWNSTREAM"""

test_images = test_images/255

from sklearn.model_selection import train_test_split
X_train_d, X_test_d, Y_train, Y_test = train_test_split(test_images, y_test, test_size=0.2)

"""#Rotation
def rotate_sample(images_):
    nlabel=images_.shape[0]
    X_train_0=images_.copy()
    X_train_90=np.rot90(images_, 1,axes=(1,2))
    X_train_180=np.rot90(images_, 2, axes=(1,2))
    X_train_270=np.rot90(images_,3, axes=(1,2))
    y_train_0=np.full((nlabel), 0)
    y_train_90=np.full((nlabel), 1)
    y_train_180=np.full((nlabel), 2)
    y_train_270=np.full((nlabel), 3)
    X_train_d=np.concatenate((X_train_0, X_train_90, X_train_180, X_train_270), axis=0)
    y_train_d=np.concatenate((y_train_0, y_train_90, y_train_180, y_train_270), axis=0)
    return X_train_d, y_train_d

X_train_d,y_train_d=rotate_sample(X_train)
X_test_d,y_test_d=rotate_sample(X_test)

_no=30
#if 80% train data 
val=8000
class_list = ['0 degree','90 degree','180 degree','270 degree']
for image_no in range(_no):
    fig = plt.figure(figsize=(15, 8))
    for i in range(4):
        ind=i*val+image_no
        ax = plt.subplot(3, 5, i + 1)
        ax.imshow(X_train_d[ind,:,:,:])
        ax.axis("off")
        ax.title.set_text(class_list[int(y_train_d[ind])])
        
print(X_train_d.shape)       
print(y_train_d.shape)
"""

class_list=np.unique(y_test)
n_classes=len(class_list)
n_classes,class_list

"""y_train_d[0],y_train_d[8000],y_train_d[16000],y_train_d[24000]"""

y_train_d=keras.utils.to_categorical(Y_train, num_classes=n_classes)
y_test_d=keras.utils.to_categorical(Y_test, num_classes=n_classes)

from sklearn.metrics import classification_report, confusion_matrix,ConfusionMatrixDisplay
def show_results(x_test_c,y_test_c,class_list,finetune_model,history):    
    Y_pred = finetune_model.predict(x_test_c)
    y_label=np.argmax(y_test_c, axis=1)
    y_pred = np.argmax(Y_pred, axis=1)
    print('Confusion Matrix')
    print(confusion_matrix(y_label, y_pred))
    cm = confusion_matrix(y_label, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_list)
    disp.plot()
    plt.show()
    FP = cm.sum(axis=0) - np.diag(cm)  
    FN = cm.sum(axis=1) - np.diag(cm)
    TP = np.diag(cm)
    TN = cm.sum() - (FP + FN + TP)

    # Sensitivity, hit rate, recall, or true positive rate
    TPR = TP/(TP+FN)
    # Specificity or true negative rate
    TNR = TN/(TN+FP) 
    # Precision or positive predictive value
    PPV = TP/(TP+FP)
    # Negative predictive value
    NPV = TN/(TN+FN)
    # Fall out or false positive rate
    FPR = FP/(FP+TN)
    # False negative rate
    FNR = FN/(TP+FN)
    # False discovery rate
    FDR = FP/(TP+FP)

    # Overall accuracy
    ACC = (TP+TN)/(TP+FP+FN+TN)
    print("Accuracy: ",round(sum(ACC)/len(class_list),2))
    print("Sensitivity: ",round(sum(TPR)/len(class_list),2))
    print("Specificity: ",round(sum(TNR)/len(class_list),2))
    print("Precision: ",round(sum(PPV)/len(class_list),2))
    print("Negative predictive value: ",round(sum(NPV)/len(class_list),2))
    print("Fall out: ",round(sum(FPR)/len(class_list),2))
    print("False negative rate: ",round(sum(FNR)/len(class_list),2))
    print("False discovery rate: ",round(sum(FDR)/len(class_list),2))

    # Plot the training and validation loss + accuracy
    acc = history.history['accuracy']
    val_acc = history.history['val_accuracy']
    epochs = range(len(acc))
    plt.xlabel("Epochs")
    plt.ylabel("Accuracy")
    plt.plot(epochs, acc, label='Training Accuracy')
    plt.plot(epochs, val_acc, label='Validation Accuracy')
    plt.legend()
    plt.title('Training and Validation Accuracy')
    plt.show()
    
    loss = history.history['loss']
    val_loss = history.history['val_loss']
    epochs = range(len(loss))
    plt.figure()
    plt.xlabel("Epochs")
    plt.ylabel("Loss")
    plt.plot(epochs, loss,'-r', label='Training Loss')
    plt.plot(epochs, val_loss, label='Validation Loss')
    plt.legend()
    plt.title('Training and Validation Loss')
    plt.show()

"""## Pre-text Weighted Model"""

#WORKDIR='results'
#generator=keras.models.load_model(os.path.join(WORKDIR, 'generator_rotary-model-cifar10.h5'))
#discriminator=keras.models.load_model(os.path.join(WORKDIR, 'disciminator_rotary-model-cifar10.h5'))

from tensorflow.keras.layers import (
    Activation, AveragePooling2D, BatchNormalization, Conv2D, Conv2DTranspose,
    Dense, Dropout, Flatten, Input, LeakyReLU, ReLU,MaxPooling2D, UpSampling2D,
    Concatenate)
from tensorflow.keras.models import Sequential, Model


def build_finetune_model(base_model, dropout, fc_layers, num_classes):
    for layer in base_model.layers:
        print(layer.name)
        layer.trainable = False

    x = base_model.get_layer("global_average_pooling2d").output
    #x = AveragePooling2D(pool_size = (4, 4), data_format = 'channels_last')(x)
    x = Flatten()(x)
    for fc in fc_layers:
        # New FC layer, random init
        
        x = Dense(fc, activation='relu')(x) 
        x = Dropout(dropout)(x)

    # New softmax layer
    #x = Dense(1024, activation='relu')(x) 
    #x = Dropout(0.5)(x)
    predictions = Dense(num_classes, activation='softmax')(x) 

    #x = Dense(64, activation = "relu")(x)
    #x = Dropout(0.5)(x)
    #x = Flatten(name = "flatten1")(x)
    #predictions = Dense(3, activation = "softmax")(x)
    
    finetune_model = Model(inputs=base_model.input, outputs=predictions)

    return finetune_model

FC_LAYERS = [1024, 1024]
dropout = 0.3

finetune_model = build_finetune_model(discriminator, dropout=dropout, fc_layers=FC_LAYERS, num_classes=n_classes)
finetune_model.summary()

from tensorflow.keras.optimizers import SGD, Adam
from tensorflow.keras.callbacks import ModelCheckpoint
import matplotlib.pyplot as plt

NUM_EPOCHS = 100
BATCH_SIZE = 16
adam = Adam(lr=0.0001)
#finetune_model.load_weights("/content/drive/MyDrive/Anam Code/pascal results/downstream/model_weights_64_0_001.h5")
finetune_model.compile(adam, loss='categorical_crossentropy', metrics=['accuracy'])
filepath="results/downstream/model_weights_cifar10_TRANSFER.h5"
checkpoint = ModelCheckpoint(filepath, monitor=["accuracy"], verbose=1, mode='max')
callbacks_list = [checkpoint]

X_train_d.shape,y_train_d.shape,X_test_d.shape,y_test_d.shape

history_rot = finetune_model.fit(X_train_d, y_train_d, epochs=NUM_EPOCHS,workers=8,verbose=1,
                             validation_split = 0.2,
                             steps_per_epoch=(X_train_d.shape[0]*0.2)//BATCH_SIZE,
                             batch_size=BATCH_SIZE, shuffle=False, callbacks=callbacks_list)

show_results(X_test_d,y_test_d,class_list,finetune_model,history_rot)

"""## MobileNet"""

from tensorflow.keras.applications.resnet50 import preprocess_input
from tensorflow.keras.applications import MobileNet
HEIGHT = 32
WIDTH = 32
base_model = MobileNet(weights=None, 
                      include_top=False, 
                      input_shape=(HEIGHT, WIDTH, 3))

from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, AveragePooling2D
from tensorflow.keras.models import Sequential, Model

def build_finetune_model(base_model, dropout, fc_layers, num_classes):
    for layer in base_model.layers:
        layer.trainable = True

    x = base_model.output
    #x = AveragePooling2D(pool_size = (4, 4), data_format = 'channels_last')(x)
    x = Flatten()(x)
    for fc in fc_layers:
        # New FC layer, random init
        
        x = Dense(fc, activation='relu')(x) 
        x = Dropout(dropout)(x)

    # New softmax layer
    #x = Dense(1024, activation='relu')(x) 
    #x = Dropout(0.5)(x)
    predictions = Dense(num_classes, activation='softmax')(x) 

    #x = Dense(64, activation = "relu")(x)
    #x = Dropout(0.5)(x)
    #x = Flatten(name = "flatten1")(x)
    #predictions = Dense(3, activation = "softmax")(x)
    
    finetune_model = Model(inputs=base_model.input, outputs=predictions)

    return finetune_model

FC_LAYERS = [1024, 1024]
dropout = 0.5

finetune_model = build_finetune_model(base_model, dropout=dropout, fc_layers=FC_LAYERS, num_classes=n_classes)
finetune_model.summary()

from tensorflow.keras.optimizers import SGD, Adam
from tensorflow.keras.callbacks import ModelCheckpoint
import matplotlib.pyplot as plt

NUM_EPOCHS = 100
BATCH_SIZE = 16


adam = Adam(lr=0.001)
#finetune_model.load_weights("/content/drive/MyDrive/Anam Code/pascal results/downstream/model_weights_64_0_001.h5")
finetune_model.compile(adam, loss='categorical_crossentropy', metrics=['accuracy'])
filepath="results/downstream_comp/model_weights_cifar10_BASE.h5"
checkpoint = ModelCheckpoint(filepath, monitor=["acc"], verbose=1, mode='max')
callbacks_list = [checkpoint]

history_base = finetune_model.fit(X_train_d, y_train_d, epochs=NUM_EPOCHS, workers=8, validation_split = 0.2,
                             steps_per_epoch=(X_train_d.shape[0]*0.2)//BATCH_SIZE,
                             batch_size=BATCH_SIZE, shuffle=False, callbacks=callbacks_list)

show_results(X_test_d,y_test_d,class_list,finetune_model,history_base)

def compare_results(history_weighted, history_baseline):    
    
    
    # Plot the training and validation loss + accuracy
    acc_b = history_baseline.history['accuracy']
    acc_w = history_weighted.history['accuracy']
    epochs = range(len(acc_w))
    plt.xlabel("Epochs")
    plt.ylabel("Accuracy")
    plt.plot(epochs, acc_b,color='green', label='From Baseline (MobileNet)')
    plt.plot(epochs, acc_w,color='blue', label='From Rotation weights')
    plt.legend()
    plt.title('Training Accuracy')
    plt.show()


    loss_b = history_baseline.history['loss']
    loss_w = history_weighted.history['loss']
    epochs = range(len(acc_w))
    plt.xlabel("Epochs")
    plt.ylabel("Loss")
    plt.plot(epochs, loss_b,color='green', label='From Baseline (MobileNet)')
    plt.plot(epochs, loss_w,color='blue', label='From Rotation weights')
    plt.legend()
    plt.title('Training Loss')
    plt.show()

compare_results(history_rot,history_base)

"""## ~~From Scratch~~

# Creating a Convolutional Neural Network
model = keras.models.Sequential([
        keras.layers.Conv2D(64, 7, activation="relu", padding="same",input_shape=[32, 32, 3]),
        keras.layers.MaxPooling2D(2),
        keras.layers.Conv2D(128, 3, activation="relu", padding="same"),
        keras.layers.Conv2D(128, 3, activation="relu", padding="same"),
        keras.layers.MaxPooling2D(2),
        keras.layers.Conv2D(256, 3, activation="relu", padding="same"),
        keras.layers.Conv2D(256, 3, activation="relu", padding="same"),
        keras.layers.MaxPooling2D(2),
        keras.layers.Flatten(),
        keras.layers.Dense(128, activation="relu"),
        #keras.layers.Dropout(0.5),
        keras.layers.Dense(64, activation="relu"),
        #keras.layers.Dropout(0.5),
        keras.layers.Dense(10, activation="softmax")
])
model.summary()
# Compiling the model
model.compile(loss="categorical_crossentropy", optimizer="Adam", metrics=["accuracy"])

history = model.fit(X_train_d, y_train_d, epochs=10, validation_data=(X_test_d, y_test_d),verbose=1)

show_results(X_test_d,y_test_d,class_list,model,history)

# *THE END*
"""